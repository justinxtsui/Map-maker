import streamlit as st
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib as mpl
import mapclassify
from matplotlib.patches import Rectangle, Circle
from matplotlib.lines import Line2D
from matplotlib.patheffects import Stroke, Normal
import os, requests, zipfile, io, numpy as np

# --------------------------- Page & fonts ---------------------------
st.set_page_config(page_title="UK Regional Company Map", layout="wide")
mpl.rcParams.update({
Â  Â  "svg.fonttype": "none",
Â  Â  "pdf.fonttype": 42,
Â  Â  "font.family": "sans-serif",
Â  Â  "font.sans-serif": ["Arial", "DejaVu Sans", "Liberation Sans"],
Â  Â  "font.weight": "regular",
Â  Â  "axes.titleweight": "bold",
Â  Â  "axes.labelweight": "regular",
})

# --------------------------- Data sources ---------------------------
GDRIVE_FILE_ID = "1ip-Aip_rQNucgdJRvIBckSnYa_RBcRFU"
SHAPEFILE_DIR = "shapefile_data"
SHAPEFILE_NAME = "NUTS_Level_1__January_2018__Boundaries.shp"

# --------------------------- Cached: download + load + simplify shapefile ---------------------------
@st.cache_resource
def load_regions_gdf():
Â  Â  """
Â  Â  Downloads the shapefile from Google Drive (if needed),
Â  Â  reads into a GeoDataFrame and simplifies geometry.
Â  Â  Cached for the whole Streamlit session.
Â  Â  """
Â  Â  os.makedirs(SHAPEFILE_DIR, exist_ok=True)
Â  Â  shp_path = os.path.join(SHAPEFILE_DIR, SHAPEFILE_NAME)

Â  Â  # Download once if missing
Â  Â  if not os.path.exists(shp_path):
Â  Â  Â  Â  url = f"https://drive.google.com/uc?export=download&id={GDRIVE_FILE_ID}"
Â  Â  Â  Â  with st.spinner("Downloading shapefile from Google Drive..."):
Â  Â  Â  Â  Â  Â  r = requests.get(url)
Â  Â  Â  Â  Â  Â  if r.status_code != 200:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Failed to download shapefile. Status code: {r.status_code}")
Â  Â  Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  Â  Â  zpath = os.path.join(SHAPEFILE_DIR, "shapefile.zip")
Â  Â  Â  Â  Â  Â  with open(zpath, "wb") as f:
Â  Â  Â  Â  Â  Â  Â  Â  f.write(r.content)
Â  Â  Â  Â  Â  Â  with zipfile.ZipFile(zpath, "r") as zf:
Â  Â  Â  Â  Â  Â  Â  Â  zf.extractall(SHAPEFILE_DIR)
Â  Â  Â  Â  Â  Â  os.remove(zpath)

Â  Â  # Load & simplify
Â  Â  os.environ["SHAPE_RESTORE_SHX"] = "YES"
Â  Â  gdf = gpd.read_file(shp_path)

Â  Â  # Light simplification for faster plotting (tweak tolerance as needed)
Â  Â  try:
Â  Â  Â  Â  gdf["geometry"] = gdf["geometry"].simplify(tolerance=500, preserve_topology=True)
Â  Â  except Exception:
Â  Â  Â  Â  # If simplify fails for any reason, just return original
Â  Â  Â  Â  pass

Â  Â  return gdf

# --------------------------- Helpers: formatting ---------------------------
# ... (format_pct_3sf and format_money_3sf functions remain unchanged) ...

def format_pct_3sf(n, total):
Â  Â  """Return n/total as a percentage string to 3 significant figures."""
Â  Â  if total <= 0:
Â  Â  Â  Â  return "0%"
Â  Â  pct = 100 * (float(n) / float(total))
Â  Â  s = f"{pct:.3g}"Â  # three significant figures; auto-scales
Â  Â  return f"{s}%"

def format_money_3sf(x):
Â  Â  """
Â  Â  Format a numeric value as money with Â£ and units (k, m, b),
Â  Â  to 3 significant figures.
Â  Â  Examples: 1234 -> Â£1.23k, 1_200_000 -> Â£1.2m, 532 -> Â£532
Â  Â  """
Â  Â  x = float(x)
Â  Â  if x == 0:
Â  Â  Â  Â  return "Â£0"
Â  Â  neg = x < 0
Â  Â  x_abs = abs(x)

Â  Â  if x_abs >= 1e9:
Â  Â  Â  Â  unit = "b"
Â  Â  Â  Â  divisor = 1e9
Â  Â  elif x_abs >= 1e6:
Â  Â  Â  Â  unit = "m"
Â  Â  Â  Â  divisor = 1e6
Â  Â  elif x_abs >= 1e3:
Â  Â  Â  Â  unit = "k"
Â  Â  Â  Â  divisor = 1e3
Â  Â  else:
Â  Â  Â  Â  unit = ""
Â  Â  Â  Â  divisor = 1.0

Â  Â  scaled = x_abs / divisor
Â  Â  s = f"{scaled:.3g}"Â  # 3 significant figures on the scaled number
Â  Â  sign = "-" if neg else ""
Â  Â  return f"{sign}Â£{s}{unit}"

# --------------------------- UI START ---------------------------

# 1. Main Area Headers (Always visible)
st.header("UK Regional Company Map Generator ðŸ—ºï¸")
st.subheader("Interactive Choropleth Map (NUTS-1 Regions)")

# 2. Load Geographical Data (Dependency Check)
gdf_regions = load_regions_gdf()

if gdf_regions is None:
Â  Â  # IMPROVED ERROR FEEDBACK
Â  Â  st.error("ðŸ›‘ **Fatal Error: Map Dependencies Missing**")
Â  Â  st.markdown("""
Â  Â  Â  Â  The application failed to load the required geographical boundary dataÂ 
Â  Â  Â  Â  (NUTS Level 1 UK regions) from the external source. The app cannot proceed.""")
Â  Â  st.stop()


# 3. Sidebar: Step 1 - Upload Data File
with st.sidebar:
Â  Â  st.header("1. Upload Data File ðŸ“‚")

Â  Â  # Use st.markdown for clear, scannable column requirements
Â  Â  st.markdown("""
Â  Â  Â  Â  To map your data, your file must contain at least **one** column
Â  Â  Â  Â  from each of the following required groups:
Â  Â  Â  Â Â 
Â  Â  Â  Â  * **Primary Region (Preferred)**:Â 
Â  Â  Â  Â  Â  Â  `Head Office Address - Region` OR `(Company) Head Office Address - Region`
Â  Â  Â  Â  * **Secondary Region (Fallback)**:Â 
Â  Â  Â  Â  Â  Â  `Registered Address - Region` OR `(Company) Registered Address - Region`
Â  Â  """)

Â  Â  # Use st.info to explain the critical merge logic
Â  Â  st.info("""
Â  Â  Â  Â  ðŸ’¡ **Mapping Logic:**
Â  Â  Â  Â  The app uses the **Primary Region** first, and falls back toÂ 
Â  Â  Â  Â  the **Secondary Region** if the primary field is blank.
Â  Â  """)

Â  Â  # Place the uploader prominently at the end of the instructions
Â  Â  uploaded = st.file_uploader("Drag and drop your file below:", type=["csv", "xlsx", "xls"])

# Stop execution if no file is uploaded yet
if not uploaded:
Â  Â  st.stop()


# --------------------------- Load file (MUST BE HERE, AFTER st.stop()) ---------------------------
ext = uploaded.name.split(".")[-1].lower()

if ext == "csv":
Â  Â  df = pd.read_csv(uploaded)
else:
Â  Â  # Excel: let user choose which sheet to use (Sheet selection must be in the main area OR sidebar)
Â  Â  xls = pd.ExcelFile(uploaded, engine="openpyxl")
Â  Â  # Placing sheet selection in the main area here is fine, as it's the first step post-upload
Â  Â  sheet_name = st.selectbox("Choose a sheet", options=xls.sheet_names, index=0)
Â  Â  df = pd.read_excel(xls, sheet_name=sheet_name, engine="openpyxl")


# --------------------------- Secondary UI (DATA-DEPENDENT: AGGREGATION & FILTERING) ---------------------------
# All controls that use `df` or rely on the data being loaded must be inside this conditional block.
with st.sidebar:
Â  Â  st.markdown("---")
Â  Â  st.header("2. Configure Metrics & Filters ðŸ”¢")

Â  Â  # --------------------------- Aggregation mode (count vs sum) ---------------------------
Â  Â  agg_mode = st.radio(
Â  Â  Â  Â  "What metric should the map show?",
Â  Â  Â  Â  ["Number of companies (row count)", "Sum a numeric column"],
Â  Â  Â  Â  index=0
Â  Â  )

Â  Â  sum_col = None
Â  Â  sum_is_money = False

Â  Â  if agg_mode == "Sum a numeric column":
Â  Â  Â  Â  numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
Â  Â  Â  Â  if not numeric_cols:
Â  Â  Â  Â  Â  Â  st.error("No numeric columns available to sum. Stopping.")
Â  Â  Â  Â  Â  Â  st.stop()
Â  Â  Â  Â  sum_col = st.selectbox("Numeric column to sum per region:", options=numeric_cols)
Â  Â  Â  Â  # Tick box for money formatting
Â  Â  Â  Â  sum_is_money = st.checkbox(
Â  Â  Â  Â  Â  Â  "Treat summed values as money (Â£ with k / m / b units, 3 s.f.)",
Â  Â  Â  Â  Â  Â  value=False
Â  Â  Â  Â  )

Â  Â  # --------------------------- Optional filtering (Using Expander for better UX) ---------------------------
Â  Â  st.markdown("---")
Â  Â  with st.expander("3. Optional Data Filter ðŸ”Ž"):
Â  Â  Â  Â  st.caption("Filter data before aggregation.")
Â  Â  Â  Â  # Note: filter_col, unique_vals, selected_vals, filter_mode now defined here
Â  Â  Â  Â  filter_col = st.selectbox("Select a column to filter:", options=df.columns, index=0)
Â  Â  Â  Â  unique_vals = df[filter_col].dropna().unique()
Â  Â  Â  Â  if len(unique_vals) > 100:
Â  Â  Â  Â  Â  Â  st.warning("Too many unique values â€” showing only the first 100 distinct values.")
Â  Â  Â  Â  Â  Â  unique_vals = unique_vals[:100]
Â  Â  Â  Â  selected_vals = st.multiselect("Select values:", options=sorted(unique_vals, key=lambda x: str(x)))
Â  Â  Â  Â  filter_mode = st.radio("Filter mode:", ["Include", "Exclude"], horizontal=True)

# NOTE: The filtering execution must happen after the controls are defined, but before processing starts.
# Applying the filter here:
if selected_vals:
Â  Â  original_row_count = len(df) # Storing original count for better feedback
Â  Â  if filter_mode == "Include":
Â  Â  Â  Â  df = df[df[filter_col].isin(selected_vals)]
Â  Â  else:
Â  Â  Â  Â  df = df[~df[filter_col].isin(selected_vals)]
Â  Â  st.success(f"Filtered to {len(df)} rows (from {original_row_count} total) based on **{filter_col}** ({filter_mode}).")


# --------------------------- Map Configuration (MOVED TO SIDEBAR) ---------------------------
with st.sidebar:
Â  Â  st.markdown("---")
Â  Â  st.header("4. Map Style & Labels ðŸŽ¨")

Â  Â  # Colour scheme selector
Â  Â  bin_mode = st.selectbox(
Â  Â  Â  Â  "Change colour scheme",
Â  Â  Â  Â  ["Tableau-like (Equal Interval)", "Quantiles", "Natural Breaks (Fisher-Jenks)", "Pretty (1â€“2â€“5)"],
Â  Â  Â  Â  index=0
Â  Â  )

Â  Â  # Custom map title (user input)
Â  Â  map_title = st.text_input("Enter your custom map title:", "UK Company Distribution by NUTS Level 1 Region")

Â  Â  # Display mode (labels)
Â  Â  display_mode = st.radio(
Â  Â  Â  Â  "Display values as:",
Â  Â  Â  Â  ["Raw value (count/sum)", "Percentage of total (3 s.f.)"],
Â  Â  Â  Â  horizontal=False # Vertical display is better in the sidebar
Â  Â  )


# --------------------------- Resolve region columns (supports "(Company) ..." variants) ---------------------------
# This logic is correctly placed here after `df` is defined.
region_col_aliases = {
Â  Â  "Head Office Address - Region": [
Â  Â  Â  Â  "Head Office Address - Region",
Â  Â  Â  Â  "(Company) Head Office Address - Region",
Â  Â  ],
Â  Â  "Registered Address - Region": [
Â  Â  Â  Â  "Registered Address - Region",
Â  Â  Â  Â  "(Company) Registered Address - Region",
Â  Â  ],
}

resolved_cols = {}
missing_canonical = []

for canonical, aliases in region_col_aliases.items():
Â  Â  found = None
Â  Â  for a in aliases:
Â  Â  Â  Â  if a in df.columns:
Â  Â  Â  Â  Â  Â  found = a
Â  Â  Â  Â  Â  Â  break
Â  Â  if found is None:
Â  Â  Â  Â  missing_canonical.append(canonical)
Â  Â  else:
Â  Â  Â  Â  resolved_cols[canonical] = found

if missing_canonical:
Â  Â  # Build a helpful error message listing accepted alternatives
Â  Â  details = []
Â  Â  for canonical, aliases in region_col_aliases.items():
Â  Â  Â  Â  alias_list = ", ".join(f"`{a}`" for a in aliases)
Â  Â  Â  Â  details.append(f"- **{canonical}**: one of {alias_list}")
Â  Â  st.error(
Â  Â  Â  Â  "Missing required region columns.\n\n"
Â  Â  Â  Â  "Please ensure your file contains at least one column for each of the following:\n\n"
Â  Â  Â  Â  + "\n".join(details)
Â  Â  )
Â  Â  st.stop()

head_col = resolved_cols["Head Office Address - Region"]
reg_col = resolved_cols["Registered Address - Region"]

# --------------------------- Clean & merge regions ---------------------------
for c in [head_col, reg_col]:
Â  Â  df[c] = (
Â  Â  Â  Â  df[c]
Â  Â  Â  Â  .astype(str)
Â  Â  Â  Â  .str.strip()
Â  Â  Â  Â  .replace({"nan": np.nan, "None": np.nan, "(no value)": np.nan, "": np.nan})
Â  Â  )

df["Region (merged)"] = df[head_col].fillna(df[reg_col])

# --------------------------- Region mapping ---------------------------
region_mapping = {
# ... (region_mapping remains unchanged) ...
Â  Â  "East Midlands": "East Midlands (England)",
Â  Â  "East of England": "East of England",
Â  Â  "London": "London",
Â  Â  "North East": "North East (England)",
Â  Â  "North West": "North West (England)",
Â  Â  "Northern Ireland": "Northern Ireland",
Â  Â  "Scotland": "Scotland",
Â  Â  "South East": "South East (England)",
Â  Â  "South West": "South West (England)",
Â  Â  "Wales": "Wales",
Â  Â  "West Midlands": "West Midlands (England)",
Â  Â  "Yorkshire and The Humber": "Yorkshire and The Humber",
Â  Â  # Scotland subregions -> Scotland
Â  Â  "West of Scotland": "Scotland",
Â  Â  "East of Scotland": "Scotland",
Â  Â  "South of Scotland": "Scotland",
Â  Â  "Highlands and Islands": "Scotland",
Â  Â  "Tayside": "Scotland",
Â  Â  "Aberdeen": "Scotland",
}
df["Region_Mapped"] = df["Region (merged)"].map(region_mapping).fillna("Unknown")

# --------------------------- Aggregate per region (COUNT or SUM) ---------------------------
valid = df[df["Region_Mapped"] != "Unknown"]

if agg_mode == "Number of companies (row count)":
Â  Â  agg_series = valid.groupby("Region_Mapped").size()
else:
Â  Â  agg_series = valid.groupby("Region_Mapped")[sum_col].sum()

counts = agg_series.reset_index(name="Region_Value")

# --------------------------- Join shapes ---------------------------
g = gdf_regions.merge(counts, left_on="nuts118nm", right_on="Region_Mapped", how="left")
g["Region_Value"] = g["Region_Value"].fillna(0)

# --------------------------- Totals ---------------------------
_total_value = float(g["Region_Value"].sum())

# --------------------------- Binning helpers ---------------------------
# ... (All binning helper functions remain unchanged) ...

def bins_equal_interval(pos_vals, k=5):
Â  Â  lo, hi = float(np.min(pos_vals)), float(np.max(pos_vals))
Â  Â  if lo == hi:
Â  Â  Â  Â  edges = [hi] * (k - 1)
Â  Â  else:
Â  Â  Â  Â  step = (hi - lo) / k
Â  Â  Â  Â  edges = [lo + step * i for i in range(1, k)]
Â  Â  return [*edges, np.inf]

def bins_quantiles(pos_vals, k=5):
Â  Â  qs = np.quantile(pos_vals, np.linspace(0, 1, k + 1))[1:-1].tolist()
Â  Â  return qs + [np.inf]

def bins_fisher_jenks(pos_vals, k=5):
Â  Â  u = np.unique(pos_vals)
Â  Â  k_eff = int(min(k, max(2, len(u))))
Â  Â  try:
Â  Â  Â  Â  fj = mapclassify.FisherJenks(pos_vals, k=k_eff)
Â  Â  Â  Â  bins = list(fj.bins[:-1]) + [np.inf]
Â  Â  Â  Â  return bins
Â  Â  except Exception:
Â  Â  Â  Â  return bins_equal_interval(pos_vals, k)

def bins_pretty_125(pos_vals, k=5):
Â  Â  lo, hi = float(np.min(pos_vals)), float(np.max(pos_vals))
Â  Â  lo_e, hi_e = int(np.floor(np.log10(lo))) - 1, int(np.ceil(np.log10(hi))) + 1
Â  Â  cands = sorted({
Â  Â  Â  Â  m * (10 ** e)
Â  Â  Â  Â  for e in range(lo_e, hi_e + 1)
Â  Â  Â  Â  for m in (1, 2, 5)
Â  Â  Â  Â  if lo <= m * (10 ** e) <= hi
Â  Â  })
Â  Â  if len(cands) >= (k - 1):
Â  Â  Â  Â  step = len(cands) / (k - 1)
Â  Â  Â  Â  edges = [cands[int(round((i + 1) * step)) - 1] for i in range(k - 1)]
Â  Â  else:
Â  Â  Â  Â  gs = np.geomspace(lo, hi, num=k).tolist()[1:-1]
Â  Â  Â  Â  edges = sorted(set([max(1, int(x)) for x in gs] + cands))
Â  Â  Â  Â  while len(edges) < (k - 1):
Â  Â  Â  Â  Â  Â  edges.append(edges[-1] + 1)
Â  Â  Â  Â  edges = edges[:k - 1]
Â  Â  for i in range(1, len(edges)):
Â  Â  Â  Â  if edges[i] <= edges[i - 1]:
Â  Â  Â  Â  Â  Â  edges[i] = edges[i - 1] + 1
Â  Â  return edges + [np.inf]

def build_bins(values, mode="Tableau-like (Equal Interval)", k=5):
Â  Â  vals = np.asarray(values, dtype=float)
Â  Â  pos = vals[vals > 0]
Â  Â  if len(pos) == 0:
Â  Â  Â  Â  return [1, 2, 3, 4, np.inf]
Â  Â  if mode.startswith("Tableau"):
Â  Â  Â  Â  return bins_equal_interval(pos, k)
Â  Â  if mode == "Quantiles":
Â  Â  Â  Â  return bins_quantiles(pos, k)
Â  Â  if mode.startswith("Natural"):
Â  Â  Â  Â  return bins_fisher_jenks(pos, k)
Â  Â  if mode.startswith("Pretty"):
Â  Â  Â  Â  return bins_pretty_125(pos, k)
Â  Â  return bins_equal_interval(pos, k)

# --------------------------- Build bins & assign colours (vectorised) ---------------------------
# Light â†’ dark violet gradient
palette = ["#E0DEE9", "#B4B1CE", "#8884B3", "#5C5799", "#302A7E"]

pos_bins = build_bins(g["Region_Value"].values, mode=bin_mode, k=len(palette))
cls = mapclassify.UserDefined(g["Region_Value"].values, bins=pos_bins)
g["bin"] = cls.yb

def pick_colour(row):
Â  Â  val = float(row["Region_Value"])
Â  Â  if val == 0:
Â  Â  Â  Â  return "#F0F0F0"
Â  Â  idx = row["bin"]
Â  Â  if idx is None or (isinstance(idx, float) and np.isnan(idx)):
Â  Â  Â  Â  idx = 0
Â  Â  idx = max(0, min(int(idx), len(palette) - 1))
Â  Â  return palette[idx]

g["face_color"] = g.apply(pick_colour, axis=1)

# --------------------------- Plot ---------------------------
# ... (Plotting code remains unchanged) ...

fig, ax = plt.subplots(figsize=(7.5, 8.5))

# Single vectorised plot call for all polygons
g.plot(ax=ax, color=g["face_color"], edgecolor="#4D4D4D", linewidth=0.5)

bounds = g.total_bounds

# Labels & callouts
label_pos = {
Â  Â  "North East": ("right", 650000), "North West": ("left", 400000),
Â  Â  "Yorkshire and The Humber": ("right", 480000), "East Midlands": ("right", 380000),
Â  Â  "West Midlands": ("left", 320000), "East of England": ("right", 280000),
Â  Â  "London": ("right", 180000), "South East": ("right", 80000),
Â  Â  "South West": ("left", 120000), "Wales": ("left", 220000),
Â  Â  "Scotland": ("left", 750000), "Northern Ireland": ("left", 500000),
}

for _, r in g.iterrows():
Â  Â  cx, cy = r.geometry.centroid.x, r.geometry.centroid.y
Â  Â  name = r["nuts118nm"].replace(" (England)", "")
Â  Â  val = float(r["Region_Value"])
Â  Â  if name not in label_pos:
Â  Â  Â  Â  continue

Â  Â  side, ty = label_pos[name]
Â  Â  if side == "left":
Â  Â  Â  Â  lx, tx, ha = bounds[0] - 30000, bounds[0] - 35000, "right"
Â  Â  else:
Â  Â  Â  Â  lx, tx, ha = bounds[2] + 30000, bounds[2] + 35000, "left"

Â  Â  circ = Circle((cx, cy), 5000, facecolor="#FFD40E", edgecolor="black", linewidth=0.5, zorder=10)
Â  Â  circ.set_path_effects([Stroke(linewidth=1.2, foreground="black"), Normal()])
Â  Â  ax.add_patch(circ)
Â  Â  ax.add_line(Line2D([cx, cx], [cy, ty], color="black", linewidth=0.8))
Â  Â  ax.add_line(Line2D([cx, lx], [ty, ty], color="black", linewidth=0.8))
Â  Â  ax.text(tx, ty, name, fontsize=11, va="bottom", ha=ha)

Â  Â  # Label value: raw or %
Â  Â  if display_mode == "Percentage of total (3 s.f.)":
Â  Â  Â  Â  label_val = format_pct_3sf(val, _total_value)
Â  Â  else:
Â  Â  Â  Â  if agg_mode == "Sum a numeric column" and sum_is_money:
Â  Â  Â  Â  Â  Â  label_val = format_money_3sf(val)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  label_val = f"{int(round(val)):,}"
Â  Â  ax.text(tx, ty - 8000, label_val, fontsize=11, va="top", ha=ha, fontweight="bold")

# Legend (min/max only) â€“ raw values (count or sum)
pos_vals = g.loc[g["Region_Value"] > 0, "Region_Value"]
if len(pos_vals) == 0:
Â  Â  min_label = "0"
Â  Â  max_label = "0"
else:
Â  Â  min_raw, max_raw = float(pos_vals.min()), float(pos_vals.max())
Â  Â  if agg_mode == "Sum a numeric column" and sum_is_money:
Â  Â  Â  Â  min_label = format_money_3sf(min_raw)
Â  Â  Â  Â  max_label = format_money_3sf(max_raw)
Â  Â  else:
Â  Â  Â  Â  min_label = f"{int(round(min_raw))}"
Â  Â  Â  Â  max_label = f"{int(round(max_raw))}"

box_w, start_x, start_y = 0.025, 0.04, 0.90
for i, col in enumerate(palette):
Â  Â  rect = Rectangle(
Â  Â  Â  Â  (start_x + i * box_w, start_y),
Â  Â  Â  Â  box_w,
Â  Â  Â  Â  box_w,
Â  Â  Â  Â  transform=fig.transFigure,
Â  Â  Â  Â  fc=col,
Â  Â  Â  Â  ec="none",
Â  Â  )
Â  Â  fig.patches.append(rect)

ax.text(
Â  Â  start_x - 0.005,
Â  Â  start_y + box_w / 2,
Â  Â  min_label,
Â  Â  transform=fig.transFigure,
Â  Â  fontsize=13,
Â  Â  va="center",
Â  Â  ha="right",
)
ax.text(
Â  Â  start_x + len(palette) * box_w + 0.005,
Â  Â  start_y + box_w / 2,
Â  Â  max_label,
Â  Â  transform=fig.transFigure,
Â  Â  fontsize=13,
Â  Â  va="center",
Â  Â  ha="left",
)

ax.set_title(map_title, fontsize=15, fontweight="bold", pad=10)
ax.axis("off")
plt.tight_layout()

# --------------------------- Show & export ---------------------------
st.pyplot(fig, use_container_width=True)

st.markdown("### Export Map")
st.markdown(
Â  Â  """
<style>
div[data-testid="column"] { flex: 1 1 45% !important; }
div[data-testid="stMarkdownContainer"] h3 { color: #000 !important; margin-bottom: 0.3rem !important; }
</style>
""",
Â  Â  unsafe_allow_html=True,
)

svg, png = io.BytesIO(), io.BytesIO()
fig.savefig(svg, format="svg", bbox_inches="tight")
svg.seek(0)
fig.savefig(png, format="png", bbox_inches="tight", dpi=300)
png.seek(0)

c1, c2 = st.columns([1, 1])
with c1:
Â  Â  # IMPROVED EXPORT MICROCOPY
Â  Â  st.markdown("### Vector Graphic (SVG)")
Â  Â  st.download_button(
Â  Â  Â  Â  "Download for Editing (.svg)",
Â  Â  Â  Â  data=svg,
Â  Â  Â  Â  file_name="uk_company_map.svg",
Â  Â  Â  Â  mime="image/svg+xml",
Â  Â  Â  Â  use_container_width=True,
Â  Â  )
with c2:
Â  Â  # IMPROVED EXPORT MICROCOPY
Â  Â  st.markdown("### High-Resolution Image (PNG)")
Â  Â  st.download_button(
Â  Â  Â  Â  "Download for Presentation (.png)",
Â  Â  Â  Â  data=png,
Â  Â  Â  Â  file_name="uk_company_map.png",
Â  Â  Â  Â  mime="image/png",
Â  Â  Â  Â  use_container_width=True,
Â  Â  )

# --------------------------- Footer image ---------------------------
st.markdown("---")
st.image(
Â  Â  "you_are_welcome.png",
Â  Â  caption="Last updated:24/10/25 -JT",
Â  Â  use_container_width=False,
Â  Â  width=175,
)
